{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyworld\n"
      ],
      "metadata": {
        "id": "CdQqySar4yk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import matplotlib.pyplot as plt\n",
        "import pyworld\n",
        "from librosa.display import specshow"
      ],
      "metadata": {
        "id": "-xmlBY1v69G9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. a. ii. The sampling frequency of the audio"
      ],
      "metadata": {
        "id": "TfnGXmlD6ikm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import matplotlib.pyplot as plt\n",
        "import pyworld\n",
        "from librosa.display import specshow\n",
        "\n",
        "# Load audio\n",
        "def load_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None, mono=True)\n",
        "    return audio, sr\n",
        "\n",
        "# Resample to a new sampling rate using scipy.signal.resample\n",
        "def resample_audio(audio, original_sr, target_sr):\n",
        "    num_samples = round(len(audio) * float(target_sr) / original_sr)\n",
        "    resampled_audio = scipy.signal.resample(audio, num_samples)\n",
        "    return resampled_audio.astype(np.float32)\n",
        "\n",
        "# Plot function\n",
        "def plot_audio_features(audio, sr):\n",
        "    # Time axis\n",
        "    time = np.arange(len(audio)) / sr\n",
        "\n",
        "    # Spectrogram\n",
        "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
        "\n",
        "    # Mel-Spectrogram\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=int(sr * 0.02), hop_length=int(sr * 0.01))\n",
        "    mel_spectrogram_db = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "    # Energy (RMS)\n",
        "    energy = librosa.feature.rms(y=audio)[0]\n",
        "\n",
        "    # Pitch contour\n",
        "    f0, time_f0 = pyworld.dio(audio, sr)\n",
        "    pitch = pyworld.stonemask(audio, f0, time_f0, sr)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Audio waveform\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(time, audio)\n",
        "    plt.title('Audio Waveform')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.ylabel('Amplitude')\n",
        "\n",
        "    # Spectrogram\n",
        "    plt.subplot(2, 2, 2)\n",
        "    specshow(D, x_axis='time', y_axis='log', sr=sr)\n",
        "    plt.title('Spectrogram')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "    # Pitch contour on spectrogram\n",
        "    plt.plot(time_f0, pitch, label='Pitch Contour', color='r', linestyle='dashed')\n",
        "    plt.legend()\n",
        "\n",
        "    # Mel-Spectrogram\n",
        "    plt.subplot(2, 2, 3)\n",
        "    specshow(mel_spectrogram_db, x_axis='time', y_axis='mel', sr=sr)\n",
        "    plt.title('Mel-Spectrogram')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "    # Energy (RMS)\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(time[:len(energy)], energy)\n",
        "    plt.title('Energy (RMS)')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.ylabel('Energy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Load and process audio\n",
        "file_path = \"your_audio_file.wav\"  # Replace with your audio file path\n",
        "audio, sr = load_audio(file_path)\n",
        "\n",
        "# Resample to 32KHz\n",
        "audio_32kHz = resample_audio(audio, sr, 32000)\n",
        "\n",
        "# Downsample to 16KHz using two methods:\n",
        "# Method 1: Taking every even sample\n",
        "audio_downsampled_even = audio_32kHz[::2]\n",
        "\n",
        "# Method 2: Resampling using scipy\n",
        "audio_downsampled_resample = resample_audio(audio_32kHz, 32000, 16000)\n",
        "\n",
        "# Plotting\n",
        "plot_audio_features(audio_32kHz, 32000)\n",
        "plot_audio_features(audio_downsampled_even, 16000)\n",
        "plot_audio_features(audio_downsampled_resample, 16000)\n",
        "\n",
        "# Listen to the outputs:\n",
        "# Use an audio player (e.g., IPython display or save the audio files to listen).\n"
      ],
      "metadata": {
        "id": "btscVmGm9To6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load audio\n",
        "def load_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None, mono=True)\n",
        "    return audio, sr\n",
        "\n",
        "# Load and process the stationary noise\n",
        "file_path = \"/content/recording.wav\"  # Replace with the noise file path\n",
        "noise, sr = librosa.load(file_path, sr=None, mono=True)"
      ],
      "metadata": {
        "id": "MD0rQ-Fa7Buq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tries:"
      ],
      "metadata": {
        "id": "I38OqheE7Zd3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSI4NL222tW4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Resample to a new sampling rate using scipy.signal.resample\n",
        "def resample_audio(audio, original_sr, target_sr):\n",
        "    num_samples = round(len(audio) * float(target_sr) / original_sr)\n",
        "    resampled_audio = scipy.signal.resample(audio, num_samples)\n",
        "    return resampled_audio.astype(np.float32)\n",
        "\n",
        "# Plot function\n",
        "def plot_audio_features(audio, sr):\n",
        "    # Time axis\n",
        "    time = np.arange(len(audio)) / sr\n",
        "\n",
        "    # Spectrogram\n",
        "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
        "\n",
        "    # Mel-Spectrogram\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=int(sr * 0.02), hop_length=int(sr * 0.01))\n",
        "    mel_spectrogram_db = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "    # Energy (RMS)\n",
        "    energy = librosa.feature.rms(y=audio)[0]\n",
        "\n",
        "    # Pitch contour\n",
        "    f0, time_f0 = pyworld.dio(audio, sr)\n",
        "    pitch = pyworld.stonemask(audio, f0, time_f0, sr)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Audio waveform\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(time, audio)\n",
        "    plt.title('Audio Waveform')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.ylabel('Amplitude')\n",
        "\n",
        "    # Spectrogram\n",
        "    plt.subplot(2, 2, 2)\n",
        "    specshow(D, x_axis='time', y_axis='log', sr=sr)\n",
        "    plt.title('Spectrogram')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "    # Pitch contour on spectrogram\n",
        "    plt.plot(time_f0, pitch, label='Pitch Contour', color='r', linestyle='dashed')\n",
        "    plt.legend()\n",
        "\n",
        "    # Mel-Spectrogram\n",
        "    plt.subplot(2, 2, 3)\n",
        "    specshow(mel_spectrogram_db, x_axis='time', y_axis='mel', sr=sr)\n",
        "    plt.title('Mel-Spectrogram')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "\n",
        "    # Energy (RMS)\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(time[:len(energy)], energy)\n",
        "    plt.title('Energy (RMS)')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.ylabel('Energy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Load and process audio\n",
        "file_path = \"recording.wav\"  # Replace with your audio file path# Load the noise audio file and resample it to 16KHz\n",
        "def load_and_resample(file_path, target_sr):\n",
        "    noise, sr = librosa.load(file_path, sr=None, mono=True)\n",
        "    noise_resampled = resample_audio(noise, sr, target_sr)\n",
        "    return noise_resampled, target_sr\n",
        "\n",
        "# Add noise to the audio\n",
        "def add_noise_to_audio(audio, noise):\n",
        "    # Truncate noise if it is longer than the audio\n",
        "    if len(noise) > len(audio):\n",
        "        noise = noise[:len(audio)]\n",
        "    # Truncate audio if it is longer than the noise\n",
        "    elif len(audio) > len(noise):\n",
        "        audio = audio[:len(noise)]\n",
        "    # Add noise to audio\n",
        "    noisy_audio = audio + noise\n",
        "    return audio, noise, noisy_audio\n",
        "\n",
        "# Plot the signals\n",
        "def plot_signals(audio, noise, noisy_audio, sr):\n",
        "    time = np.arange(len(audio)) / sr\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Plot original audio\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(time, audio)\n",
        "    plt.title(\"Original Audio\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "\n",
        "    # Plot noise\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.plot(time, noise)\n",
        "    plt.title(\"Noise\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "\n",
        "    # Plot noisy audio\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(time, noisy_audio)\n",
        "    plt.title(\"Noisy Audio\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Load and process the stationary noise\n",
        "noise_file_path = \"stationary_noise.wav\"  # Replace with the noise file path\n",
        "noise, noise_sr = load_and_resample(noise_file_path, 16000)\n",
        "\n",
        "# Use one of the downsampled audio signals from Q1.c.2 (e.g., audio_downsampled_resample)\n",
        "audio_downsampled_resample = resample_audio(audio_32kHz, 32000, 16000)\n",
        "\n",
        "# Add noise to the audio\n",
        "audio, noise, noisy_audio = add_noise_to_audio(audio_downsampled_resample, noise)\n",
        "\n",
        "# Plot the results\n",
        "plot_signals(audio, noise, noisy_audio, 16000)\n",
        "\n",
        "audio, sr = load_audio(file_path)\n",
        "\n",
        "# Resample to 32KHz\n",
        "audio_32kHz = resample_audio(audio, sr, 32000)\n",
        "\n",
        "# Downsample to 16KHz using two methods:\n",
        "# Method 1: Taking every even sample\n",
        "audio_downsampled_even = audio_32kHz[::2]\n",
        "\n",
        "# Method 2: Resampling using scipy\n",
        "audio_downsampled_resample = resample_audio(audio_32kHz, 32000, 16000)\n",
        "\n",
        "# Plotting\n",
        "plot_audio_features(audio_32kHz, 32000)\n",
        "plot_audio_features(audio_downsampled_even, 16000)\n",
        "plot_audio_features(audio_downsampled_resample, 16000)\n",
        "\n",
        "# Listen to the outputs:\n",
        "# Use an audio player (e.g., IPython display or save the audio files to listen).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the noise audio file and resample it to 16KHz\n",
        "def load_and_resample(file_path, target_sr):\n",
        "    noise, sr = librosa.load(file_path, sr=None, mono=True)\n",
        "    noise_resampled = resample_audio(noise, sr, target_sr)\n",
        "    return noise_resampled, target_sr\n",
        "\n",
        "# Add noise to the audio\n",
        "def add_noise_to_audio(audio, noise):\n",
        "    # Truncate noise if it is longer than the audio\n",
        "    if len(noise) > len(audio):\n",
        "        noise = noise[:len(audio)]\n",
        "    # Truncate audio if it is longer than the noise\n",
        "    elif len(audio) > len(noise):\n",
        "        audio = audio[:len(noise)]\n",
        "    # Add noise to audio\n",
        "    noisy_audio = audio + noise\n",
        "    return audio, noise, noisy_audio\n",
        "\n",
        "# Plot the signals\n",
        "def plot_signals(audio, noise, noisy_audio, sr):\n",
        "    time = np.arange(len(audio)) / sr\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Plot original audio\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(time, audio)\n",
        "    plt.title(\"Original Audio\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "\n",
        "    # Plot noise\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.plot(time, noise)\n",
        "    plt.title(\"Noise\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "\n",
        "    # Plot noisy audio\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(time, noisy_audio)\n",
        "    plt.title(\"Noisy Audio\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Load and process the stationary noise\n",
        "noise_file_path = \"stationary_noise.wav\"  # Replace with the noise file path\n",
        "noise, noise_sr = load_and_resample(noise_file_path, 16000)\n",
        "\n",
        "# Use one of the downsampled audio signals from Q1.c.2 (e.g., audio_downsampled_resample)\n",
        "audio_downsampled_resample = resample_audio(audio_32kHz, 32000, 16000)\n",
        "\n",
        "# Add noise to the audio\n",
        "audio, noise, noisy_audio = add_noise_to_audio(audio_downsampled_resample, noise)\n",
        "\n",
        "# Plot the results\n",
        "plot_signals(audio, noise, noisy_audio, 16000)\n"
      ],
      "metadata": {
        "id": "LkpwJFwH3QKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import scipy.signal\n",
        "import matplotlib.pyplot as plt\n",
        "from librosa.display import specshow\n",
        "\n",
        "# Compute short-term energy\n",
        "def compute_energy(audio, sr, window_size, hop_size):\n",
        "    frame_length = int(sr * window_size)\n",
        "    hop_length = int(sr * hop_size)\n",
        "    energy = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "    time = librosa.frames_to_time(np.arange(len(energy)), sr=sr, hop_length=hop_length)\n",
        "    return energy, time\n",
        "\n",
        "# Voice Activity Detection (VAD)\n",
        "def vad(audio, sr, energy, threshold_ratio=0.1):\n",
        "    threshold = threshold_ratio * np.max(energy)\n",
        "    vad_mask = energy > threshold\n",
        "    return vad_mask, threshold\n",
        "\n",
        "# Spectral Subtraction\n",
        "def spectral_subtraction(noisy_audio, sr, vad_mask, window_size, hop_size):\n",
        "    # Compute STFT\n",
        "    stft_noisy = librosa.stft(noisy_audio, n_fft=int(sr * window_size), hop_length=int(sr * hop_size))\n",
        "    magnitude_noisy = np.abs(stft_noisy)\n",
        "    phase_noisy = np.angle(stft_noisy)\n",
        "\n",
        "    # Estimate noise spectrum\n",
        "    noise_frames = magnitude_noisy[:, ~vad_mask]\n",
        "    noise_estimation = np.mean(noise_frames, axis=1, keepdims=True)\n",
        "\n",
        "    # Spectral subtraction\n",
        "    magnitude_enhanced = magnitude_noisy - noise_estimation\n",
        "    magnitude_enhanced = np.maximum(magnitude_enhanced, 0)  # Avoid negative values\n",
        "\n",
        "    # Reconstruct enhanced signal\n",
        "    stft_enhanced = magnitude_enhanced * np.exp(1j * phase_noisy)\n",
        "    enhanced_audio = librosa.istft(stft_enhanced, hop_length=int(sr * hop_size))\n",
        "    return enhanced_audio\n",
        "\n",
        "# Plotting results\n",
        "def plot_energy_and_vad(audio, sr, energy, time, vad_mask, threshold):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(time, energy, label=\"Energy\")\n",
        "    plt.axhline(y=threshold, color='r', linestyle='--', label=\"Threshold\")\n",
        "    plt.fill_between(time, 0, energy, where=vad_mask, alpha=0.3, label=\"Speech Regions\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Energy\")\n",
        "    plt.title(\"Energy Contour with VAD Threshold\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Main workflow\n",
        "def enhance_audio(noisy_audio, sr):\n",
        "    # Parameters\n",
        "    window_size = 0.02  # 20ms\n",
        "    hop_size = 0.01     # 10ms\n",
        "\n",
        "    # Compute energy\n",
        "    energy, time = compute_energy(noisy_audio, sr, window_size, hop_size)\n",
        "\n",
        "    # VAD\n",
        "    vad_mask, threshold = vad(noisy_audio, sr, energy)\n",
        "\n",
        "    # Plot energy contour and VAD regions\n",
        "    plot_energy_and_vad(noisy_audio, sr, energy, time, vad_mask, threshold)\n",
        "\n",
        "    # Apply spectral subtraction\n",
        "    enhanced_audio = spectral_subtraction(noisy_audio, sr, vad_mask, window_size, hop_size)\n",
        "\n",
        "    return enhanced_audio\n",
        "\n",
        "# Load noisy audio (from Q2.b)\n",
        "noisy_audio, sr = noisy_audio, 16000  # Assuming 16KHz sampling rate from Q2.b\n",
        "\n",
        "# Enhance the noisy audio\n",
        "enhanced_audio = enhance_audio(noisy_audio, sr)\n",
        "\n",
        "# Plot the results using the function from Q1.d\n",
        "plot_audio_features(enhanced_audio, sr)\n"
      ],
      "metadata": {
        "id": "ReZxwNmc5Nh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "DESIRED_RMS_DB = -20  # Desired RMS in dB\n",
        "NOISE_FLOOR_DB = -50  # Noise floor threshold in dB\n",
        "WINDOW_SIZE = 1.0  # 1 second window for RMS calculation\n",
        "HOP_SIZE = 0.01    # 10ms hop size\n",
        "SIGMOID_ALPHA = 10  # Sigmoid parameter for clipping prevention\n",
        "\n",
        "# Convert dB to linear scale\n",
        "def db_to_linear(db):\n",
        "    return 10**(db / 20)\n",
        "\n",
        "# Compute RMS for sliding window\n",
        "def compute_rms(audio, sr, window_size, hop_size):\n",
        "    frame_length = int(sr * window_size)\n",
        "    hop_length = int(sr * hop_size)\n",
        "    rms = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "    time = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)\n",
        "    return rms, time\n",
        "\n",
        "# Apply AGC\n",
        "def auto_gain_control(audio, sr, desired_rms_db, noise_floor_db, window_size, hop_size, sigmoid_alpha):\n",
        "    # Convert to linear scale\n",
        "    desired_rms = db_to_linear(desired_rms_db)\n",
        "    noise_floor = db_to_linear(noise_floor_db)\n",
        "\n",
        "    # Compute RMS\n",
        "    rms, time = compute_rms(audio, sr, window_size, hop_size)\n",
        "\n",
        "    # Calculate gain\n",
        "    gain = np.zeros_like(rms)\n",
        "    for i in range(len(rms)):\n",
        "        if rms[i] > noise_floor:\n",
        "            gain[i] = desired_rms / rms[i]\n",
        "        else:\n",
        "            gain[i] = 1.0  # No amplification for noise\n",
        "\n",
        "    # Smooth gain over time\n",
        "    gain_smoothed = scipy.signal.medfilt(gain, kernel_size=5)\n",
        "\n",
        "    # Apply gain to audio\n",
        "    frame_length = int(sr * window_size)\n",
        "    hop_length = int(sr * hop_size)\n",
        "    enhanced_audio = np.zeros_like(audio)\n",
        "    for i, g in enumerate(gain_smoothed):\n",
        "        start = i * hop_length\n",
        "        end = start + frame_length\n",
        "        enhanced_audio[start:end] += audio[start:end] * g\n",
        "\n",
        "    # Apply sigmoid to prevent overflow\n",
        "    enhanced_audio = 1 / (1 + np.exp(-sigmoid_alpha * enhanced_audio))\n",
        "\n",
        "    return enhanced_audio, gain_smoothed, time\n",
        "\n",
        "# Plot scaling factors vs. time\n",
        "def plot_scaling_factors(time, gain):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(time, gain)\n",
        "    plt.title(\"Scaling Factors vs Time\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Gain Factor\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Main workflow\n",
        "def apply_agc(audio, sr):\n",
        "    # Apply AGC\n",
        "    enhanced_audio, gain, time = auto_gain_control(\n",
        "        audio, sr, DESIRED_RMS_DB, NOISE_FLOOR_DB, WINDOW_SIZE, HOP_SIZE, SIGMOID_ALPHA\n",
        "    )\n",
        "\n",
        "    # Plot enhanced audio using function from Q1.d\n",
        "    plot_audio_features(enhanced_audio, sr)\n",
        "\n",
        "    # Plot scaling factors\n",
        "    plot_scaling_factors(time, gain)\n",
        "\n",
        "    return enhanced_audio\n",
        "\n",
        "# Load audio from Q1.c.2\n",
        "audio, sr = audio_downsampled_resample, 16000  # Assuming 16KHz sampling rate from Q1.c.2\n",
        "\n",
        "# Apply AGC\n",
        "enhanced_audio = apply_agc(audio, sr)\n"
      ],
      "metadata": {
        "id": "KWyEA-n45Yd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "SPEED_FACTOR = 1.5\n",
        "WINDOW_SIZE = 2048  # Window size for STFT\n",
        "HOP_SIZE = 512      # Hop size for STFT\n",
        "\n",
        "# Load the audio\n",
        "audio, sr = audio_downsampled_resample, 16000  # Assuming 16KHz audio from Q1.c.2\n",
        "\n",
        "# Time-stretching using phase vocoder\n",
        "def phase_vocoder_time_stretch(audio, sr, speed_factor, window_size, hop_size):\n",
        "    # Compute STFT\n",
        "    stft_matrix = librosa.stft(audio, n_fft=window_size, hop_length=hop_size)\n",
        "    magnitude, phase = np.abs(stft_matrix), np.angle(stft_matrix)\n",
        "\n",
        "    # Time-stretching\n",
        "    n_frames = stft_matrix.shape[1]\n",
        "    stretched_frames = int(n_frames / speed_factor)\n",
        "    new_indices = np.linspace(0, n_frames - 1, stretched_frames)\n",
        "    stretched_magnitude = magnitude[:, new_indices.astype(int)]\n",
        "\n",
        "    # Recalculate phase using phase propagation\n",
        "    phase_advances = np.diff(phase, axis=1)\n",
        "    phase_advances = np.pad(phase_advances, ((0, 0), (1, 0)), mode='constant')\n",
        "    new_phase = np.cumsum(phase_advances[:, new_indices.astype(int)], axis=1)\n",
        "    stretched_stft = stretched_magnitude * np.exp(1j * new_phase)\n",
        "\n",
        "    # Apply iSTFT\n",
        "    stretched_audio = librosa.istft(stretched_stft, hop_length=hop_size)\n",
        "\n",
        "    return stretched_audio\n",
        "\n",
        "# Time-stretch the audio\n",
        "stretched_audio = phase_vocoder_time_stretch(audio, sr, SPEED_FACTOR, WINDOW_SIZE, HOP_SIZE)\n",
        "\n",
        "# Plot time-domain signals\n",
        "def plot_time_domain(original, stretched, sr):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    librosa.display.waveshow(original, sr=sr)\n",
        "    plt.title(\"Original Audio (Time Domain)\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    librosa.display.waveshow(stretched, sr=sr)\n",
        "    plt.title(\"Time-Stretched Audio (Time Domain)\")\n",
        "    plt.xlabel(\"Time [sec]\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot spectral domain\n",
        "def plot_spectral_domain(original, stretched, sr):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    D_original = librosa.amplitude_to_db(np.abs(librosa.stft(original)), ref=np.max)\n",
        "    librosa.display.specshow(D_original, sr=sr, x_axis='time', y_axis='log')\n",
        "    plt.title(\"Original Audio (Spectral Domain)\")\n",
        "    plt.colorbar(format=\"%+2.0f dB\")\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    D_stretched = librosa.amplitude_to_db(np.abs(librosa.stft(stretched)), ref=np.max)\n",
        "    librosa.display.specshow(D_stretched, sr=sr, x_axis='time', y_axis='log')\n",
        "    plt.title(\"Time-Stretched Audio (Spectral Domain)\")\n",
        "    plt.colorbar(format=\"%+2.0f dB\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the results\n",
        "plot_time_domain(audio, stretched_audio, sr)\n",
        "plot_spectral_domain(audio, stretched_audio, sr)\n",
        "\n",
        "# Listen to the result\n",
        "import IPython.display as ipd\n",
        "print(\"Original Audio:\")\n",
        "ipd.display(ipd.Audio(audio, rate=sr))\n",
        "print(\"Time-Stretched Audio:\")\n",
        "ipd.display(ipd.Audio(stretched_audio, rate=sr))\n"
      ],
      "metadata": {
        "id": "PXozdESQ5tiT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}